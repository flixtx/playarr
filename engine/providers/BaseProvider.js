import { createLogger } from '../utils/logger.js';
import axios from 'axios';
import Bottleneck from 'bottleneck';
import fs from 'fs-extra';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

/**
 * Base class for all providers (IPTV, TMDB, etc.)
 * Provides generic API communication, caching, and data storage functionality
 * @abstract
 */
export class BaseProvider {
  /**
   * Load all enabled provider configurations from MongoDB
   * @param {import('../services/MongoDataService.js').MongoDataService} mongoData - MongoDB data service instance
   * @returns {Promise<Object[]>} Array of provider configuration objects, sorted by priority
   */
  static async loadProviders(mongoData) {
    if (!mongoData) {
      const logger = createLogger('BaseProvider');
      logger.error('MongoDataService is required to load providers');
      throw new Error('MongoDataService is required');
    }

    try {
      // Query enabled providers from MongoDB, sorted by priority
      const providers = await mongoData.getIPTVProviders();
      
      // Filter enabled providers (should already be filtered by getIPTVProviders, but double-check)
      const enabledProviders = providers.filter(p => p.enabled !== false);
      
      // Sort by priority (lower number = higher priority)
      return enabledProviders.sort((a, b) => (a.priority || 999) - (b.priority || 999));
    } catch (error) {
      const logger = createLogger('BaseProvider');
      logger.error(`Error loading providers from MongoDB: ${error.message}`);
      throw error;
    }
  }

  /**
   * @param {Object} providerData - Provider configuration data
   * @param {import('../managers/StorageManager.js').StorageManager} cache - Storage manager instance for temporary cache
   * @param {string} [loggerContext] - Optional logger context override
   */
  constructor(providerData, cache, loggerContext = null) {
    this.providerData = providerData;
    this.cache = cache;
    this.providerId = providerData.id || 'default';

    // Create logger with custom context or default to provider type
    const context = loggerContext || `${providerData.type?.toUpperCase() || 'PROVIDER'}::${this.providerId}`;
    this.logger = createLogger(context);

    // Create rate limiter from provider config
    const rateConfig = providerData.api_rate || { concurrent: 1, duration_seconds: 1 };
    const concurrent = rateConfig.concurrent || rateConfig.concurrect || 1; // Handle typo "concurrect"
    const durationSeconds = rateConfig.duration_seconds || 1;
    
    // Use reservoir pattern for true rate limiting (N requests per duration_seconds)
    // This prevents bursts and ensures exactly N requests per time window
    this.limiter = new Bottleneck({
      reservoir: concurrent, // Number of requests allowed
      reservoirRefreshInterval: durationSeconds * 1000, // Refresh interval in ms
      reservoirRefreshAmount: concurrent, // How many requests to add back
      maxConcurrent: concurrent, // Max concurrent requests
      minTime: 0 // No minimum time between requests, reservoir handles it
    });
    
    this.logger.debug(`Rate limiter configured: ${concurrent} requests per ${durationSeconds} second(s)`);
    
    // Instance-level progress tracking: { 'movies': { count: 642, saveCallback: fn } }
    this._progressTracking = {};
    
    // Single progress interval per provider instance
    this._progressInterval = null;
    
    // In-memory cache for this provider's policies
    this._cachePolicies = null; // Will be loaded via initializeCachePolicies()
  }

  /**
   * Start progress interval if not already running
   * @private
   */
  _startProgressInterval() {
    if (this._progressInterval) {
      return; // Already running
    }

    this._progressInterval = setInterval(() => {
      this._logProgress();
    }, 30000); // 30 seconds

    this.logger.debug('Progress interval started');
  }

  /**
   * Stop progress interval if running
   * @private
   */
  _stopProgressInterval() {
    if (this._progressInterval) {
      clearInterval(this._progressInterval);
      this._progressInterval = null;
      this.logger.debug('Progress interval stopped');
    }
  }

  /**
   * Log progress for all active types and trigger save callbacks
   * @private
   */
  _logProgress() {
    const activeTypes = Object.entries(this._progressTracking)
      .filter(([type, data]) => data.count > 0)
      .map(([type, data]) => `${type}: ${data.count}`);

    if (activeTypes.length > 0) {
      this.logger.info(`Progress update - ${activeTypes.join(', ')} title(s) remaining to process`);
      
      // Call save callbacks for each active type (every 30 seconds)
      Object.entries(this._progressTracking).forEach(([type, data]) => {
        if (data.count > 0 && data.saveCallback) {
          data.saveCallback();
        }
      });
    } else {
      // Stop interval if no active types
      this._stopProgressInterval();
    }
  }

  /**
   * Register a type for progress tracking
   * @param {string} type - Media type ('movies', 'tvshows', etc.)
   * @param {number} count - Initial remaining count
   * @param {Function} [saveCallback] - Optional callback to save accumulated titles
   */
  registerProgress(type, count, saveCallback = null) {
    this._progressTracking[type] = { count, saveCallback };
    if (count > 0) {
      this._startProgressInterval();
    }
  }

  /**
   * Update progress for a type
   * @param {string} type - Media type ('movies', 'tvshows', etc.)
   * @param {number} count - Updated remaining count
   */
  updateProgress(type, count) {
    if (this._progressTracking[type]) {
      this._progressTracking[type].count = count;
    }
    
    // Check if all types are done
    const allDone = Object.values(this._progressTracking).every(data => data.count === 0);
    if (allDone) {
      this._stopProgressInterval();
    }
  }

  /**
   * Unregister a type from progress tracking
   * @param {string} type - Media type ('movies', 'tvshows', etc.)
   */
  unregisterProgress(type) {
    // Call save callback one last time before unregistering
    const data = this._progressTracking[type];
    if (data && data.saveCallback) {
      data.saveCallback();
    }
    
    delete this._progressTracking[type];
    
    // Check if all types are done
    const allDone = Object.values(this._progressTracking).every(data => data.count === 0);
    if (allDone) {
      this._stopProgressInterval();
    }
  }

  /**
   * Get default cache policies for this provider
   * Override in subclasses to define provider-specific policies
   * @returns {Object} Cache policy object with key-value pairs
   */
  getDefaultCachePolicies() {
    // Base implementation returns empty - subclasses should override
    return {};
  }

  /**
   * Initialize cache policies for this provider
   * Loads from MongoDB, creates defaults if missing
   * Must be called after construction
   * @returns {Promise<void>}
   */
  async initializeCachePolicies() {
    if (!this.cache || !this.cache.mongoData) {
      this.logger.warn('Cache manager or MongoDB not available, skipping cache policy initialization');
      this._cachePolicies = {};
      return;
    }

    try {
      const defaultPolicies = this.getDefaultCachePolicies();
      if (Object.keys(defaultPolicies).length === 0) {
        // No policies defined for this provider
        this._cachePolicies = {};
        return;
      }

      // Get existing policies from MongoDB for this provider's keys
      const existingPolicies = await this.cache.mongoData.getCachePolicies();
      
      // Filter to only this provider's policies
      const providerPolicies = {};
      const policiesToCreate = {};
      
      for (const [key, defaultValue] of Object.entries(defaultPolicies)) {
        if (existingPolicies.hasOwnProperty(key)) {
          // Policy exists in MongoDB, use it
          providerPolicies[key] = existingPolicies[key];
        } else {
          // Policy doesn't exist, use default and create it
          providerPolicies[key] = defaultValue;
          policiesToCreate[key] = defaultValue;
        }
      }

      // Create missing policies in MongoDB
      if (Object.keys(policiesToCreate).length > 0) {
        this.logger.info(`Initializing ${Object.keys(policiesToCreate).length} cache policies for ${this.providerId}`);
        const promises = Object.entries(policiesToCreate).map(([key, value]) =>
          this.cache.mongoData.updateCachePolicy(key, value, this.providerId)
        );
        await Promise.all(promises);
      }

      // Store in provider's memory
      this._cachePolicies = providerPolicies;
      
      // Also register with StorageManager's shared cache
      if (this.cache.registerCachePolicies) {
        this.cache.registerCachePolicies(providerPolicies);
      }

      this.logger.debug(`Cache policies initialized for ${this.providerId}: ${Object.keys(providerPolicies).length} policies`);
    } catch (error) {
      this.logger.error(`Error initializing cache policies: ${error.message}`);
      // Fallback to defaults in memory
      this._cachePolicies = this.getDefaultCachePolicies();
    }
  }

  /**
   * Fetch data from API with caching support
   * Checks cache first and validates expiration based on cache-policy.json, then fetches from API if cache doesn't exist, is expired, or forceRefresh is true
   * @param {string} url - API URL to fetch from
   * @param {string[]} cacheKeyParts - Cache key parts array (e.g., [providerId, 'metadata', 'movies.json'])
   * @param {number|null} [ttlHours=1] - TTL in hours (null for Infinity). Used to update cache policy.
   * @param {boolean} [forceRefresh=false] - Force refresh even if cache exists
   * @param {Object} [options] - Additional axios options (headers, etc.)
   * @returns {Promise<Object>} API response data
   */
  async fetchWithCache(url, cacheKeyParts, ttlHours = 1, forceRefresh = false, options = {}) {
    // Convert Infinity to null for JSON storage
    const ttl = ttlHours === Infinity ? null : ttlHours;

    // Check cache first - verify it exists AND is not expired
    if (!forceRefresh && cacheKeyParts.length > 0) {
      const cached = this.cache.get(...cacheKeyParts);
      if (cached) {
        // Check if cache is expired based on policy
        const isExpired = this.cache.isExpired(...cacheKeyParts);
        if (!isExpired) {
          this.logger.debug(`Loading from cache: ${cacheKeyParts.join('/')}`);
          return cached;
        } else {
          this.logger.debug(`Cache expired for: ${cacheKeyParts.join('/')}, fetching fresh data`);
        }
      }
    }

    this.logger.debug(`Fetching from API: ${url}`);
    // Wrap API call with rate limiter
    const response = await this.limiter.schedule(() => axios.get(url, options));
    
    if (cacheKeyParts.length > 0) {
      // Pass TTL to cache.set() to update policy (now async)
      await this.cache.set(response.data, ttl, ...cacheKeyParts);
    }

    return response.data;
  }
}
